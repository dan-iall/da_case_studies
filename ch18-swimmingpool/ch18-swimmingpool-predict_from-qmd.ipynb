{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Prepared for Gabor's Data Analysis\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "### Data Analysis for Business, Economics, and Policy\n",
        "by Gabor Bekes and  Gabor Kezdi\n",
        " \n",
        "Cambridge University Press 2021\n",
        "\n",
        "**[gabors-data-analysis.com ](https://gabors-data-analysis.com/)**\n",
        "\n",
        " License: Free to share, modify and use for educational purposes. \n",
        " Not to be used for commercial purposes.\n",
        "\n",
        "### Chapter 18\n",
        "**CH18 Forecasting daily ticket sales for a swimming pool**\n",
        "\n",
        "using swim data\n",
        "\n",
        "version 0.9.0 2025-08-14\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Frieren's Grimoire: Bringing tools from the void\n",
        "# ---------------------------------------------------------\n",
        "import os  # Operating System: The map to our file locations\n",
        "import sys  # System: To manipulate the path of our journey\n",
        "import warnings  # Warnings: To silence the minor spirits\n",
        "from datetime import datetime  # Time: To understand the flow of ages\n",
        "\n",
        "import numpy as np  # NumPy: The fundamental math of the elves\n",
        "import pandas as pd  # Pandas: The table-manipulation magic\n",
        "import seaborn as sns  # Seaborn: To weave beautiful visual illusions\n",
        "from matplotlib import pyplot as plt  # Matplotlib: The canvas for our art\n",
        "import pandas_market_calendars as mcal  # Calendars: Knowledge of the holidays\n",
        "import pyfixest as pf  # PyFixest: High-performance econometric spells\n",
        "from sklearn.metrics import root_mean_squared_error  # RMSE: The judge of our accuracy\n",
        "\n",
        "# Silencing warnings to keep the mind clear\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Setting the Path: Where does our journey begin?\n",
        "# ---------------------------------------------------------\n",
        "# Current script folder - finding our feet\n",
        "current_path = os.getcwd()\n",
        "dirname = current_path.split(\"da_case_studies\")[0]\n",
        "\n",
        "# Defining the locations of our artifacts (Directories)\n",
        "data_in = dirname + \"da_data_repo/swim-transactions/clean/\"\n",
        "data_out = dirname + \"da_case_studies/ch18-swim-transactions/\"\n",
        "output = dirname + \"da_case_studies/ch18-swim-transactions/output/\"\n",
        "func = dirname + \"da_case_studies/ch00-tech-prep/\"\n",
        "\n",
        "# Adding the function directory to our spellbook path\n",
        "sys.path.append(func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import py_helper_functions as da\n",
        "\n",
        "# Set custom color scheme for plots - The Robes of the Mage\n",
        "sns.set_theme(rc=da.da_theme, palette=da.color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The Pandas Lexicon - Dates\n",
        "**Mage Sight (Eye Movement):** Focus on `parse_dates=[\"date\"]`.\n",
        "\n",
        "In the ancient tongue of CSV, dates are but mere strings (Text). A common apprentice mistake is to leave them as such.\n",
        "*   **The Artifact:** `pd.read_csv(..., parse_dates=...)`\n",
        "*   **The Transformation:** `String Class` $\\to$ `Timestamp Class`\n",
        "*   **Why it matters:** Accessing parts of a date (Year/Month) from a String requires slow regex parsing. A `Timestamp` object stores time as a 64-bit integer (nanoseconds since 1970), allowing for instant O(1) retrieval.\n",
        "\n",
        "**Arch-Mage Note:** If you forget this, your future spells (like `.dt.year`) will fail with an `AttributeError`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the scroll (CSV) and interpreting the \"date\" runes immediately\n",
        "daily_agg = pd.read_csv(os.path.join(data_in, \"swim_work.csv\"), parse_dates=[\"date\"])\n",
        "# daily_agg = pd.read_csv(\"https://osf.io/download/jcxmk/\", parse_dates=[\"date\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>QUANTITY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-02</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-03</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  QUANTITY\n",
              "0 2010-01-01         0\n",
              "1 2010-01-02        49\n",
              "2 2010-01-03        31\n",
              "3 2010-01-04        14\n",
              "4 2010-01-05        18"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The Mage's First Glance: Inspecting the head of the beast\n",
        "daily_agg.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The `.dt` Accessor\n",
        "**Mage Sight:** Look at `daily_agg[\"date\"].dt.year`.\n",
        "\n",
        "This `.dt` is a specialized \"Namespace Accessor\".\n",
        "*   **The Concept:** A Series (column) in Pandas usually holds generic Objects. But if it holds Timestamps, the `.dt` accessor exposes the C-level attributes of the underlying array.\n",
        "*   **Efficiency:** `daily_agg[\"date\"].year` would fail. You *Must* go through the gate of `.dt`.\n",
        "*   **Vectorization:** This extraction happens in the C-layer, processing millions of rows instantly, unlike a Python loop.\n",
        "\n",
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: List Membership\n",
        "**Mage Sight:** Look at `.isin([6, 7])`.\n",
        "*   **The Logic:** `x in [6, 7]` is Python. `.isin([6, 7])` is Pandas.\n",
        "*   **The Difference:** The Pandas version checks the entire column at once, returning a Boolean Array (True/False) of the same length `(N)`.\n",
        "\n",
        "**Mana Flow:** `Timestamp Column` $\\to$ `.dt` $\\to$ `Integer Attributes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracting time components using the .dt accessor\n",
        "daily_agg[\"year\"] = daily_agg[\"date\"].dt.year # The Year (e.g., 2015)\n",
        "daily_agg[\"quarter\"] = daily_agg[\"date\"].dt.quarter # The Quarter (1-4)\n",
        "daily_agg[\"month\"] = daily_agg[\"date\"].dt.month # The Month (1-12)\n",
        "daily_agg[\"day\"] = daily_agg[\"date\"].dt.day # The Day of the month (1-31)\n",
        "daily_agg[\"dow\"] = daily_agg[\"date\"].dt.dayofweek + 1 # Day of Week (Mon=1, Sun=7)\n",
        "\n",
        "# Identifying Weekends: Is the day Saturday (6) or Sunday (7)?\n",
        "daily_agg[\"weekend\"] = daily_agg[\"dow\"].isin([6, 7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: Boolean Masks (Bitwise Logic)\n",
        "**Mage Sight:** Focus on the `&` and `|` symbols.\n",
        "\n",
        "You might ask: *\"why not use `and` / `or`?\"*\n",
        "*   **Python Logic:** `and` checks the \"Truthiness\" of an entire object.\n",
        "*   **Bitwise Logic (`&`, `|`):** These operators compare array elements *position-by-position*.\n",
        "    *   `[True, False] & [True, True] -> [True, False]`\n",
        "*   **Parentheses:** They are **mandatory** here. `daily_agg[\"day\"] > 15 & ...` would crash because `&` has higher precedence than `>`. The parentheses force the comparison to happen first.\n",
        "\n",
        "**The Spell:** We are constructing a \"Mask\" (Screen).\n",
        "*   **Input:** Multiple Boolean Arrays.\n",
        "*   **Output:** A single Boolean Array `(N,)`, where True means \"School was Closed\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the \"School Off\" mask using Bitwise Logic (&, |)\n",
        "# Parentheses are critical here to enforce order of operations!\n",
        "daily_agg[\"school_off\"] = (\n",
        "    ((daily_agg[\"day\"] > 15) & (daily_agg[\"month\"] == 5) & (daily_agg[\"day\"] <= 30)) # Late May\n",
        "    | ((daily_agg[\"month\"] == 6) | (daily_agg[\"month\"] == 7)) # June or July (Support Summer)\n",
        "    | ((daily_agg[\"day\"] < 15) & (daily_agg[\"month\"] == 8)) # Early August\n",
        "    | ((daily_agg[\"day\"] > 20) & (daily_agg[\"month\"] == 12)) # Late December (Winter Break)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a simple linear trend for time\n",
        "daily_agg[\"trend\"] = daily_agg.index + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get holiday calendar ----------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: External Knowledge\n",
        "**Mage Sight:** `mcal.get_calendar(\"NYSE\")`.\n",
        "\n",
        "Sometimes the data you need involves complexity defined elsewhere (like holiday rules). Be lazy. Use a library that encodes this knowledge (`pandas_market_calendars`).\n",
        "\n",
        "**The Join Logic:**\n",
        "*   `.isin(holidays)`: This is effectively a \"Left Join\" check.\n",
        "*   **True**: The date exists in the holiday list.\n",
        "*   **False**: It does not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "```{python}\n",
        "nyse = mcal.get_calendar(\"NYSE\")\n",
        "\n",
        "holidays = nyse.holidays().holidays\n",
        "\n",
        "daily_agg[\"isHoliday\"] = daily_agg[\"date\"].isin(holidays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A quick glance at the numerical summaries (Distribution Check)\n",
        "daily_agg.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: Broadcast vs. Aggregate\n",
        "**Mage Sight:** `daily_agg.groupby(\"month\")[\"QUANTITY\"].transform(\"mean\")`\n",
        "\n",
        "This is a subtle but powerful spell.\n",
        "1.  **Split:** Break the data into 12 piles (one for each month).\n",
        "2.  **Apply:** Calculate the `mean` of Quantity for each pile.\n",
        "    *   *Result so far:* A series of length 12 (Jan=150, Feb=140...).\n",
        "3.  **Broadcast (`transform`):** This is the key. Instead of returning the 12 summaries, Pandas *pastes* the Jan-Average next to *every* January row in the original dataset.\n",
        "\n",
        "**Shape Mechanics:**\n",
        "*   `.agg(\"mean\")` $\\to$ Returns shape `(12,)` (Group Summary).\n",
        "*   `.transform(\"mean\")` $\\to$ Returns shape `(N,)` (Original Size).\n",
        "\n",
        "**Why?** We want to regress \"Daily Stats\" against \"Monthly Averages\". To do that, they must be in the same DataFrame.\n",
        "\n",
        "### Define vars for analysis\n",
        "\n",
        "### Define vars for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Monthly Seasonality (Mean Quantity per Month)\n",
        "daily_agg[\"q_month\"] = daily_agg.groupby(\"month\")[\"QUANTITY\"].transform(\"mean\")\n",
        "\n",
        "# 2. Log Transformation (Stabilizing the Variance)\n",
        "daily_agg[\"q_ln\"] = np.log(daily_agg[\"QUANTITY\"])\n",
        "\n",
        "# Handling the Void (Inf/-Inf): Replace infinite values with NaN so they don't break the model\n",
        "daily_agg[\"q_ln\"] = daily_agg[\"q_ln\"].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 3. Weekly Seasonality within Months (Mean Quantity per Month-DayOfWeek combination)\n",
        "daily_agg[\"tickets\"] = daily_agg.groupby([\"month\", \"dow\"])[\"QUANTITY\"].transform(\"mean\")\n",
        "\n",
        "# 4. Log Version of Weekly Seasonality\n",
        "daily_agg[\"tickets_ln\"] = daily_agg.groupby([\"month\", \"dow\"])[\"q_ln\"].transform(\"mean\")\n",
        "\n",
        "# 5. Abbreviations for visualization (e.g., 'Mon', 'Jan')\n",
        "daily_agg[\"dow_abb\"] = daily_agg[\"date\"].dt.day_name().str[:3]\n",
        "daily_agg[\"month_abb\"] = daily_agg[\"date\"].dt.month_name().str[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descriptive graphs\n",
        "\n",
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The Art of Time-Series Visualization\n",
        "**Mage Sight:** `sns.lineplot(...)`\n",
        "\n",
        "A simple spell, but one that requires precise calibration.\n",
        "*   **The Filter:** We slice time `data[year == 2015]`. Plotting *everything* creates a messy \"hairball\". Zooming in reveals the rhythm.\n",
        "*   **The Ticks:** `plt.xticks`. By default, Matplotlib might label the axis with incomprehensible numbers. We force it to speak our language (`%d%b%Y` -> 01Jan2015)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Focusing on a single year (2015) to see the daily rhythm\n",
        "filtered_data = daily_agg[daily_agg[\"year\"] == 2015].reset_index()\n",
        "\n",
        "# Drawing the line of time\n",
        "sns.lineplot(data=filtered_data, x=\"date\", y=\"QUANTITY\", linewidth=0.6)\n",
        "\n",
        "# Calibrating the X-Axis labels (The tick marks)\n",
        "date_ticks = [\"2015-01-01\", \"2015-04-01\", \"2015-07-01\", \"2015-10-01\", \"2016-01-01\"]\n",
        "plt.xticks(date_ticks, [pd.to_datetime(date).strftime(\"%d%b%Y\") for date in date_ticks])\n",
        "\n",
        "# Labelling the axes for the observer\n",
        "plt.xlabel(\"Date (day)\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_data = daily_agg.loc[\n",
        "    (daily_agg.year >= 2010) & (daily_agg.year <= 2014), :\n",
        "].reset_index()\n",
        "\n",
        "sns.lineplot(data=filtered_data, x=\"date\", y=\"QUANTITY\", linewidth=0.3)\n",
        "date_ticks = [\n",
        "    \"2010-01-01\",\n",
        "    \"2011-01-01\",\n",
        "    \"2012-01-01\",\n",
        "    \"2013-01-01\",\n",
        "    \"2014-01-01\",\n",
        "    \"2015-01-01\",\n",
        "]\n",
        "plt.xticks(date_ticks, [pd.to_datetime(date).strftime(\"%d%b%Y\") for date in date_ticks])\n",
        "plt.xlabel(\"Date (day)\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: Reading the Box Plot (The Quartile Grimoire)\n",
        "**Mage Sight:** `sns.boxplot(...)`.\n",
        "\n",
        "A Box Plot is a spell that summarizes the *Distribution* of mana (data).\n",
        "*   **The Box:** The middle 50% of the data (Interquartile Range - IQR). From the 25th percentile to the 75th.\n",
        "*   **The Line:** The Median (50th percentile). The heart of the distribution.\n",
        "*   **The Whiskers:** The range of \"Normal\" data (usually 1.5x IQR).\n",
        "*   **The Diamonds (Fliers):** Rare events (Outliers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the Order: We force the months to align with the calendar, not the alphabet\n",
        "month_order = [\n",
        "    \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
        "    \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\",\n",
        "]\n",
        "\n",
        "# Summoning the Box Plot\n",
        "sns.boxplot(\n",
        "    data=daily_agg,\n",
        "    x=\"month_abb\", # Grouping by Month\n",
        "    y=\"QUANTITY\", # analyzing Ticket Sales\n",
        "    fliersize=3, # Size of the outlier diamonds\n",
        "    order=month_order, # Enforcing our custom order\n",
        "    flierprops={\n",
        "        \"markerfacecolor\": da.color[3], # coloring the outliers\n",
        "        \"markeredgecolor\": da.color[3],\n",
        "        \"alpha\": 0.6,\n",
        "    },\n",
        "    boxprops={\"facecolor\": \"white\", \"edgecolor\": da.color[0]},\n",
        "    whiskerprops={\"color\": da.color[0]},\n",
        "    medianprops={\"color\": da.color[0], \"linewidth\": 2},\n",
        "    showcaps=False,\n",
        ")\n",
        "plt.yticks(np.arange(0, 400, 100)) # Calibrating the Y-axis\n",
        "plt.xlabel(\"Date (month)\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.grid(axis=\"x\", color=\"gray\", linestyle=\"-\", linewidth=0.5) # Adding a grid for precision\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the Order of Days (Monday first!)\n",
        "dow_order = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
        "\n",
        "# Summoning the Box Plot for Days of the Week\n",
        "sns.boxplot(\n",
        "    data=daily_agg,\n",
        "    x=\"dow_abb\",\n",
        "    y=\"QUANTITY\",\n",
        "    fliersize=3,\n",
        "    order=dow_order,\n",
        "    flierprops={\n",
        "        \"markerfacecolor\": da.color[3],\n",
        "        \"markeredgecolor\": da.color[3],\n",
        "        \"alpha\": 0.6,\n",
        "    },\n",
        "    boxprops={\"facecolor\": \"white\", \"edgecolor\": da.color[0]},\n",
        "    whiskerprops={\"color\": da.color[0]},\n",
        "    medianprops={\"color\": da.color[0], \"linewidth\": 2},\n",
        "    showcaps=False,\n",
        ")\n",
        "plt.yticks(np.arange(0, 400, 100))\n",
        "plt.xlabel(\"Day of the week\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.grid(axis=\"x\", color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: Categorical Data & Ordered Factors\n",
        "**Mage Sight:** `pd.Categorical(..., ordered=True)`.\n",
        "\n",
        "Strings like \"Mon\", \"Tue\"... have no inherent order to a computer. Alphabetically, \"Fri\" comes before \"Mon\". This is chaos.\n",
        "*   **The Fix:** We define a `Categorical` type with a specific `categories` list.\n",
        "*   **The Effect:** When we later sort or plot, \"Mon\" will correctly appear before \"Tue\", and \"Jan\" before \"Feb\", honoring the laws of time rather than the alphabet.\n",
        "\n",
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: Thermal Vision (The Heatmap)\n",
        "**Mage Sight:** `pivot(...)` + `heatmap(...)`.\n",
        "\n",
        "This spell reveals the density of mana across two dimensions (Time X Time).\n",
        "1.  **Pivot:** We must reshape the data from Long (\"Row per day\") to Wide (\"Rows=Month, Cols=Day\"). This is the Matrix format.\n",
        "2.  **Heatmap:** We apply a color gradients (`viridis_r`) to this matrix. Lighter colors = High Traffic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to check for interactions, look at the heatmap\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# Enforcing Order on the Dimensions\n",
        "daily_agg[\"dow_abb_ordered\"] = pd.Categorical(\n",
        "    daily_agg[\"dow_abb\"], categories=dow_order, ordered=True\n",
        ")\n",
        "daily_agg[\"month_abb_ordered\"] = pd.Categorical(\n",
        "    daily_agg[\"month_abb\"], categories=reversed(month_order), ordered=True\n",
        ")\n",
        "\n",
        "# Aggregating: Calculating Mean Tickets for each (Month, Day) pair\n",
        "agg_data = daily_agg.groupby([\"month_abb_ordered\", \"dow_abb_ordered\"], as_index=False)[\n",
        "    \"tickets\"\n",
        "].mean()\n",
        "\n",
        "# Pivoting: The Transformation to Matrix Form\n",
        "heatmap_data = agg_data.pivot(\n",
        "    index=\"month_abb_ordered\", columns=\"dow_abb_ordered\", values=\"tickets\"\n",
        ")\n",
        "\n",
        "# Summoning the Heatmap\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    cmap=\"viridis_r\", # The color palette (Reversed Viridis)\n",
        "    linewidths=0.5, # Grid lines\n",
        "    linecolor=\"white\",\n",
        "    cbar_kws={\"shrink\": 0.4, \"aspect\": 5}, # Configuring the Legend Bar\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Day of the week\")\n",
        "plt.ylabel(\"Month\")\n",
        "plt.yticks(rotation=0) # Keeping Y-labels horizontal for readability\n",
        "\n",
        "# Adjusting the Color Bar (The Scale of Magic)\n",
        "cbar = plt.gca().collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "cbar.set_label(\"Tickets\", fontsize=10)\n",
        "cbar.set_ticks([50, 100, 150])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# not in book\n",
        "# Repeating the Spell for Log-Transformed Data\n",
        "plt.figure(figsize=(9, 6))\n",
        "agg_data = daily_agg.groupby([\"month_abb_ordered\", \"dow_abb_ordered\"], as_index=False)[\n",
        "    \"tickets_ln\"\n",
        "].mean()\n",
        "\n",
        "heatmap_data = agg_data.pivot(\n",
        "    index=\"month_abb_ordered\", columns=\"dow_abb_ordered\", values=\"tickets_ln\"\n",
        ")\n",
        "\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    cmap=\"viridis_r\",\n",
        "    linewidths=0.5,\n",
        "    linecolor=\"white\",\n",
        "    cbar_kws={\"shrink\": 0.4, \"aspect\": 5, \"label\": \"Log tickets\"},\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Day of the week\")\n",
        "plt.ylabel(\"Month\")\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "cbar = plt.gca().collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\n",
        "\n",
        "### Creat train/holdout data\n",
        "\n",
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The Chronological Split\n",
        "**Mage Sight:** `daily_agg.loc[...]` with strict year barriers.\n",
        "\n",
        "In normal magic (standard Machine Learning), we use `train_test_split(shuffle=True)`.\n",
        "*   **The Forbidden Technique:** Shuffling is forbidden in Time Series.\n",
        "*   **Why?** If you shuffle, you might train on tomorrow to predict yesterday. This is \"Look-ahead Bias\".\n",
        "*   **The Syntax:** We manually slice `.loc[data[\"year\"] < 2016]` (The Past) and `== 2016` (The Future).\n",
        "\n",
        "**Mana Flow:** `(All Data)` $\\to$ `(Past, Future)`\n",
        "**Arch-Mage Note:** Strict temporal separation prevents data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Preparing the Factor columns (Categories)\n",
        "factor_cols = [\"month\", \"dow\", \"isHoliday\", \"school_off\"]\n",
        "daily_agg[factor_cols] = daily_agg[factor_cols].astype(\"category\")\n",
        "\n",
        "# 2. The Holdout Set (The Future: 2016)\n",
        "data_holdout = daily_agg.loc[daily_agg[\"year\"] == 2016, :]\n",
        "\n",
        "# 3. The Training Set (The Past: 2010-2015)\n",
        "data_train = daily_agg.loc[daily_agg[\"year\"] < 2016, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The Manual Cross-Validation Loop\n",
        "**Mage Sight:** Focus on the `for` loop and the `.loc` inside it.\n",
        "\n",
        "Standard libraries (`sklearn.model_selection.KFold`) are often insufficient for complex time structures. We must weave our own Validation Spell.\n",
        "\n",
        "**The Loop Anatomy:**\n",
        "1.  **Select the Test Year:** `data[group_col] == test_set` (e.g., Year 2010).\n",
        "2.  **Select the Training Years:** `data[group_col] != test_set` (All other years).\n",
        "3.  **Train & Predict:** Fit on the \"Other Years\", Predict on the \"Single Year\".\n",
        "4.  **Accumulate:** `rmse_folds.append(rmse)`.\n",
        "\n",
        "**Syntax Note (Scope):** `rmse_folds = []` is defined *outside* the loop. The loop mutates it by appending results. This is the classic \"Accumulator Pattern\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frieren: A custom spell to iterate through time periods\n",
        "def inserted_test_set_cv(\n",
        "    formula: str,\n",
        "    data: pd.DataFrame,\n",
        "    group_col: str,\n",
        "    correct_log_transformation_bias: bool = False,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Perform inserted test set cross-validation.\n",
        "    \"\"\"\n",
        "    # 1. Input Parsing: Extracting the target variable name (Left side of ~)\n",
        "    y_variable = formula.split(\"~\")[0].strip()\n",
        "    \n",
        "    # 2. Cleaning: Dropping missing values in the target to avoid errors\n",
        "    data = data.dropna(subset=[y_variable])\n",
        "\n",
        "    # 3. Identifying the Epochs (Years) to iterate over\n",
        "    test_sets = data[group_col].unique()\n",
        "    rmse_folds = [] # The Accumulator for our results\n",
        "\n",
        "    # 4. The Loop of Time\n",
        "    for test_set in test_sets:\n",
        "        # Define Training Data: Everything EXCEPT the current test year\n",
        "        data_train = data.loc[data[group_col] != test_set, :]\n",
        "        \n",
        "        # Define Test Data: ONLY the current test year\n",
        "        data_test = data.loc[data[group_col] == test_set, :]\n",
        "\n",
        "        # 5. Training the Model (Fitting the spell)\n",
        "        model = pf.feols(formula, data=data_train)\n",
        "\n",
        "        # 6. Forecasting\n",
        "        y_hat = model.predict(data_test)\n",
        "        y_true = data_test[y_variable]\n",
        "        \n",
        "        # 7. Evaluating Accuracy (RMSE)\n",
        "        rmse = root_mean_squared_error(y_true, y_hat)\n",
        "\n",
        "        # 8. Correction for Log-Models (If we predicted log(y), we must convert back)\n",
        "        if correct_log_transformation_bias:\n",
        "            # Applying the correction factor exp(sigma^2 / 2)\n",
        "            y_hat = np.exp(y_hat) * np.exp(rmse**2 / 2)\n",
        "            y_true = np.exp(y_true)\n",
        "            # Re-calculating RMSE in the original scale\n",
        "            rmse = root_mean_squared_error(y_true, y_hat)\n",
        "\n",
        "        # Storing the result\n",
        "        rmse_folds.append(rmse)\n",
        "\n",
        "    # Frieren: aggregating the shards of time into a single truth (Mean Probability)\n",
        "    return np.mean(rmse_folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Frieren's Grimoire: Defining the complexity tiers\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Model 1: The Simplest Spell (Linear Trend + Month)\n",
        "model1 = \"QUANTITY ~ trend + month\"\n",
        "\n",
        "# Model 2: Adding Weekly Rhythms (+ Day of Week)\n",
        "model2 = \"QUANTITY ~ trend + month + dow\"\n",
        "\n",
        "# Model 3: Injecting External Knowledge (+ Holidays)\n",
        "model3 = \"QUANTITY ~ trend + month + dow + isHoliday\"\n",
        "\n",
        "# Model 4: Handling Special Events (+ School Off Interaction)\n",
        "# Note: 'school_off*dow' adds both the main effect and the interaction\n",
        "model4 = \"QUANTITY ~ trend + month + dow + isHoliday + school_off*dow\"\n",
        "\n",
        "# Model 5: The Grand Arch-Mage Spell (Full Complexity)\n",
        "# Adding interactions between Weekend and Month (Summer weekends vs Winter weekends)\n",
        "model5 = \"QUANTITY ~ trend + month + dow + isHoliday + school_off*dow + weekend*month\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The Evaluation Ritual: Testing each spell against the flow of time\n",
        "cross_validated_rmses = []\n",
        "\n",
        "for model in [model1, model2, model3, model4, model5]:\n",
        "    # Running the Temporal Cross-Validation\n",
        "    rmse = inserted_test_set_cv(model, data_train, \"year\")\n",
        "    cross_validated_rmses.append(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 6: The Logarithmic Alteration\n",
        "# Sometimes mana flows exponentially. We take the log() to make it linear.\n",
        "model6 = \"q_ln ~ trend + month + dow + isHoliday + school_off*dow\"\n",
        "\n",
        "# We must fix the bias when converting back from Log-World to Real-World\n",
        "rmse6 = inserted_test_set_cv(\n",
        "    model6, data_train, \"year\", correct_log_transformation_bias=True\n",
        ")\n",
        "cross_validated_rmses.append(rmse6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use prophet prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation\n",
        "from prophet.diagnostics import performance_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Deciphering: Summoning the Prophet\n",
        "**The Spell Anatomy:**\n",
        "* `Prophet(...)`: Initializing the additive model structure (Trend + Seasonality).\n",
        "* `add_country_holidays`: Injecting the Guild's calendar (US Holidays).\n",
        "\n",
        "**Mana Flow:** `(ds, y)` $\\to$ `(Forecast Model)`\n",
        "**Arch-Mage Note:** Prophet requires a specific data shape: columns named `ds` (date) and `y` (target). It is strict about this naming convention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frieren: Initializing the Oracle. Note 'additive' seasonality.\n",
        "model_prophet = Prophet(\n",
        "    seasonality_mode=\"additive\", # Adding effects (Trend + Season + Holiday)\n",
        "    yearly_seasonality=\"auto\", # Detecting annual cycles automatically\n",
        "    weekly_seasonality=\"auto\", # Detecting weekly cycles\n",
        "    growth=\"linear\", # Assuming linear growth over time\n",
        "    daily_seasonality=True, # Accounting for daily patterns\n",
        ")\n",
        "\n",
        "# Injecting the knowledge of US Holidays into the Oracle\n",
        "model_prophet = Prophet.add_country_holidays(model_prophet, \"US\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the Oracle to the Past\n",
        "model_prophet = Prophet.fit(\n",
        "    model_prophet,\n",
        "    # Frieren: The Oracle demands 'ds' and 'y' columns. We must comply.\n",
        "    df=data_train[[\"date\", \"QUANTITY\"]].rename({\"date\": \"ds\", \"QUANTITY\": \"y\"}, axis=1),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generating the Cross-Validation folds (Temporal Backtesting)\n",
        "cv_pred = cross_validation(\n",
        "    model_prophet, \n",
        "    initial=\"365 days\", # Training on at least 1 year\n",
        "    period=\"365 days\", # Moving forward by 1 year at a time\n",
        "    horizon=\"365 days\" # Predicting 1 year into the future\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracting the RMSE from the Oracle's visions\n",
        "rmse_prophet_cv = performance_metrics(cv_pred, rolling_window=1)[\"rmse\"].values[0]\n",
        "cross_validated_rmses.append(rmse_prophet_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: M6 log model rmse is slightly different from book\n",
        "pd.DataFrame(\n",
        "    cross_validated_rmses,\n",
        "    [\"M\" + str(i) for i in range(1, 6)] + [\"M6 (log)\", \"M7 (Prophet)\"],\n",
        "    columns=[\"RMSE\"],\n",
        ").round(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate best model on holdout set\n",
        "\n",
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Deciphering: The Final Verdict\n",
        "**The Spell Anatomy:**\n",
        "* `best_model.predict`: We use the model trained on *all* history (2010-2015) to predict the future (2016).\n",
        "* `root_mean_squared_error`: The judge.\n",
        "\n",
        "**Mana Flow:** `(Holdout Data)` $\\to$ `(Predictions)` $\\to$ `(Error Metric)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = pf.feols(model5, data=data_train)\n",
        "\n",
        "data_holdout[\"y_hat_5\"] = best_model.predict(data_holdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse_holdout_best = root_mean_squared_error(data_holdout.QUANTITY, data_holdout.y_hat_5)\n",
        "rmse_holdout_best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot best predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# graph relative RMSE (on holdout) per month\n",
        "\n",
        "group = data_holdout.sort_values(by=[\"date\"]).groupby(\"month\")\n",
        "rmse_monthly = pd.DataFrame(\n",
        "    {\n",
        "        \"date\": group[\"date\"].first(),\n",
        "        \"RMSE\": group.apply(\n",
        "            lambda x: root_mean_squared_error(x[\"QUANTITY\"], x[\"y_hat_5\"])\n",
        "        ),\n",
        "        \"RMSE_norm\": group.apply(\n",
        "            lambda x: root_mean_squared_error(x[\"QUANTITY\"], x[\"y_hat_5\"])\n",
        "            / np.mean(x[\"QUANTITY\"])\n",
        "        ),\n",
        "    }\n",
        ").reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 18.7 b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.barplot(x=\"date\", y=\"RMSE_norm\", data=rmse_monthly)\n",
        "ax.set_xticklabels(rmse_monthly[\"date\"].dt.strftime(\"%b\"))\n",
        "ax.set_yticks(np.arange(0, 1.6, 0.5))\n",
        "ax.set_xlabel(\"Date (month)\")\n",
        "ax.set_ylabel(\"RMSE (normalized by monthly sales)\")\n",
        "plt.grid(axis=\"x\", color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßù‚Äç‚ôÄÔ∏è Frieren's Seminar: The Unpivot (Melt)\n",
        "**Mage Sight:** `dataset.melt(...)`\n",
        "\n",
        "To plot multiple lines (Actual vs Predicted), plotting libraries (Seaborn/Ggplot) demand **\"Tidy\" (Long) Data**.\n",
        "*   **The Problem:** Our data is \"Wide\". We have separate columns `QUANTITY` and `y_hat`.\n",
        "*   **The Solution (`melt`):** We collapse these two columns into one.\n",
        "    *   `variable` column: Contains the names \"QUANTITY\" or \"y_hat\".\n",
        "    *   `value` column: Contains the numbers.\n",
        "\n",
        "**Method Chaining (`.`):**\n",
        "Notice the parentheses usage `( ... )`. This allows us to chain multiple operations (`filter` -> `melt` -> `merge` -> `rename`) without creating intermediate variables like `df_temp1`, `df_temp2`. This is cleaner syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frieren: Reshaping the timeline into a long format for the Sea-born Plotter (Seaborn)\n",
        "plotdata = (\n",
        "    data_holdout\n",
        "    .filter([\"date\", \"month\", \"QUANTITY\", \"y_hat_5\"]) # Select only essential mana streams\n",
        "    .melt(id_vars=[\"date\", \"month\"]) # Unpivot: Collapsing Qty and Prediction into one column\n",
        "    # Re-attaching the original values for reference (Self-Join)\n",
        "    .merge(data_holdout.filter([\"date\", \"QUANTITY\"]), on=\"date\") \n",
        "    .merge(data_holdout.filter([\"date\", \"y_hat_5\"]), on=\"date\")\n",
        "    # Renaming for clarity in the legend\n",
        "    .rename(columns={\"QUANTITY\": \"ymin\", \"y_hat_5\": \"ymax\"})\n",
        "    .assign(\n",
        "        variable=lambda x: x[\"variable\"].map(\n",
        "            {\"QUANTITY\": \"Actual\", \"y_hat_5\": \"Predicted\"} # Renaming the labels\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 18.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.lineplot(x=\"date\", y=\"value\", hue=\"variable\", style=\"variable\", data=plotdata)\n",
        "\n",
        "xticks = pd.to_datetime(\n",
        "    [\"2016-01-01\", \"2016-03-01\", \"2016-05-01\", \"2016-07-01\", \"2016-09-01\", \"2016-11-01\"]\n",
        ")\n",
        "xlabels = [\"01Jan2016\", \"01Mar2016\", \"01May2016\", \"01Jul2016\", \"01Sep2016\", \"01Nov2016\"]\n",
        "plt.xticks(xticks, labels=xlabels, fontsize=9)\n",
        "plt.xlim((datetime(2016, 1, 1), datetime(2017, 1, 1)))\n",
        "plt.xlabel(\"Date (day)\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.legend(bbox_to_anchor=(0.54, 0.77), frameon=False, ncol=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 18.7 a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frieren: Focusing the mage sight on a single month (August) to inspect the fine details.\n",
        "plotdata_august = plotdata[plotdata[\"month\"] == 8].reset_index()\n",
        "sns.lineplot(\n",
        "    x=\"date\",\n",
        "    y=\"value\",\n",
        "    hue=\"variable\",\n",
        "    style=\"variable\",\n",
        "    data=plotdata_august,\n",
        "    linewidth=1.5,\n",
        ")\n",
        "\n",
        "plt.fill_between(\n",
        "    plotdata_august.loc[lambda x: x[\"variable\"] == \"Actual\", \"date\"],\n",
        "    plotdata_august.loc[lambda x: x[\"variable\"] == \"Actual\", \"ymin\"],\n",
        "    plotdata_august.loc[lambda x: x[\"variable\"] == \"Actual\", \"ymax\"],\n",
        "    color=da.color[3],\n",
        "    alpha=0.2,\n",
        ")\n",
        "plt.xticks(\n",
        "    pd.to_datetime(\n",
        "        [\"2016-08-01\", \"2016-08-08\", \"2016-08-15\", \"2016-08-22\", \"2016-08-29\"]\n",
        "    ),\n",
        "    labels=[\"01Aug\", \"08Aug\", \"15Aug\", \"22Aug\", \"29Aug\"],\n",
        ")\n",
        "plt.ylim(0, 150)\n",
        "plt.xlim((datetime(2016, 8, 1), datetime(2016, 8, 31)))\n",
        "plt.yticks(np.arange(0, 151, 50))\n",
        "plt.xlabel(\"Date (day)\")\n",
        "plt.ylabel(\"Daily ticket sales\")\n",
        "plt.legend(\n",
        "    title=\"\", loc=\"upper left\", bbox_to_anchor=(0.54, 0.77), frameon=False, ncol=2\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
